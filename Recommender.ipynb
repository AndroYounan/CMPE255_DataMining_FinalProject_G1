{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f5a4d18",
   "metadata": {},
   "source": [
    "# Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3791f0a8-c723-4a8c-84f8-10d2c422c840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import LoadUtils\n",
    "import pandas as pd\n",
    "\n",
    "PATH_BUSINESS = 'yelp_dataset/yelp_academic_dataset_business.json'\n",
    "PATH_REVIEW = 'yelp_dataset/yelp_academic_dataset_review.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b87f85-dbb3-429c-b46e-c80df6f52f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommend to set to a low value like 100,000 for quicker iteration.\n",
    "# Set to -1 to load the full files, which will make processing SIGNIFICANTLY slower.\n",
    "N_LINES = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5335c077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for OPEN ONLY businesses in California\n",
    "data_business = LoadUtils.load_matches(PATH_BUSINESS, n_lines=N_LINES, verbose=True,\n",
    "                                       func=LoadUtils.fn_all,\n",
    "                                       args=[(LoadUtils.fn_eq, \"state\", \"CA\"),\n",
    "                                             (LoadUtils.fn_eq, \"is_open\", 1)])\n",
    "business_ca_open = pd.DataFrame(data_business)\n",
    "\n",
    "# Display filtered data\n",
    "print(f\"Number of open businesses in California: {business_ca_open.shape[0]}\")\n",
    "print(business_ca_open.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07c9de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "biz_ids = set()\n",
    "for item in data_business:\n",
    "    biz_ids.add(item[\"business_id\"])\n",
    "\n",
    "# full data is 7 million entries, so this takes pretty long (around 3 minutes)\n",
    "data_review = LoadUtils.load_matches(PATH_REVIEW, n_lines=N_LINES, verbose=True,\n",
    "                                     func=LoadUtils.fn_in,\n",
    "                                     args=(\"business_id\", biz_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795622a2-4e32-440a-8b06-99452ab5dc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review = pd.DataFrame(data_review)\n",
    "review_ca_open = df_review.drop(labels=['stars', 'useful', 'funny', 'cool', 'date'], axis=1)\n",
    "\n",
    "# Display filtered reviews\n",
    "print(f\"{len(set(review_ca_open['user_id']))} users\" + \\\n",
    "      f\" made {len(set(review_ca_open['review_id']))} reviews\" + \\\n",
    "      f\" across {len(set(review_ca_open['business_id']))} businesses\")\n",
    "print(review_ca_open.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23426d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell takes pretty long on larger data, 4-5 minutes\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Convert the textual reviews into a numerical representation using TF-IDF (Term Frequency-Inverse Document Frequency)\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=5000)  # Limit to 5000 most important terms\n",
    "review_tfidf = tfidf.fit_transform(review_ca_open['text'])\n",
    "\n",
    "print(f\"TF-IDF Matrix Shape: {review_tfidf.shape}\")  # High-dimensional representation\n",
    "\n",
    "# Apply Dimentionality Reduction using Principal Component Analysis (PCA)\n",
    "pca = PCA(n_components=50)  # Reduce to 50 components\n",
    "reduced_reviews = pca.fit_transform(review_tfidf.toarray())\n",
    "\n",
    "print(f\"Reduced Dimensions Shape: {reduced_reviews.shape}\")  # Lower-dimensional representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95a1d31",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba623a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Determine the best number of clusters using Elbow Method\n",
    "inertia = []\n",
    "k_values = range(2, 30+1)\n",
    "\n",
    "print(\"Now clustering with k=\", end='')\n",
    "for k in k_values:\n",
    "    print(f\" {k}...\", end='')\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(reduced_reviews)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the Elbow Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(k_values, inertia, marker='o', linestyle='--')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5473a4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply K-Means with the chosen number of clusters based on the Elbow Curve\n",
    "optimal_k = 20\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "clusters = kmeans.fit_predict(reduced_reviews)\n",
    "\n",
    "clustered_reviews = review_ca_open[['review_id', 'user_id', 'business_id']]\n",
    "clustered_reviews = clustered_reviews.assign(cluster=pd.Series(clusters))\n",
    "print(clustered_reviews.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb7c580-c685-4638-b42c-c9141103072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_of(k):\n",
    "    \"\"\"\n",
    "    Given a df column name, make a new df that associates the named\n",
    "    attribute to the cluster that it most commonly belongs to.\n",
    "    \"\"\"\n",
    "    output = clustered_reviews.groupby(\n",
    "        [k, 'cluster']).size().reset_index(name='occurrence')\n",
    "    output = output.loc[\n",
    "        output.groupby(k)['occurrence'].idxmax()\n",
    "    ]\n",
    "    return output.drop('occurrence', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2117284-9eea-491c-b6c9-804ae0aeb565",
   "metadata": {},
   "outputs": [],
   "source": [
    "biz_cluster = get_cluster_of('business_id')\n",
    "user_cluster = get_cluster_of('user_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b3db32",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9577058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_businesses(user_id, num_recommendations=5):\n",
    "    # Get the cluster that the user belongs to\n",
    "    c = user_cluster[user_cluster['user_id'] == user_id]['cluster'].values[0]\n",
    "    \n",
    "    # Get all businesses in this cluster\n",
    "    businesses = biz_cluster[biz_cluster['cluster'] == c]\n",
    "    \n",
    "    # Exclude businesses the user has already reviewed\n",
    "    reviewed_businesses = clustered_reviews[clustered_reviews['user_id'] == user_id]['business_id'].unique()\n",
    "    recommendations = businesses[~businesses['business_id'].isin(reviewed_businesses)]\n",
    "\n",
    "    # Select top businesses for recommendation (or fewer if less available)\n",
    "    recommendations = recommendations.sample(n=min(num_recommendations, len(recommendations)))\n",
    "    recommendations = recommendations.merge(business_ca_open[['business_id', 'name', 'categories']], on='business_id')\n",
    "    return recommendations[['name', 'categories']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f4565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = user_cluster.iloc[999]['user_id']\n",
    "\n",
    "recs = recommend_businesses(uid)\n",
    "print(f\"For user with id {uid}, these are the recommendations:\")\n",
    "print(recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbdb70b-2381-48b2-a8f4-95e32fb138d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find insights for users and business owners using Association Rules\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Prepare data for Apriori (one-hot encoding)\n",
    "user_cluster_matrix = clustered_reviews.pivot_table(\n",
    "    index='user_id', columns='cluster', aggfunc='size', fill_value=0\n",
    ")\n",
    "user_cluster_matrix = user_cluster_matrix.applymap(lambda x: True if x > 0 else False)\n",
    "\n",
    "# Apply Apriori algorithm to find frequent itemsets\n",
    "frequent_itemsets = apriori(user_cluster_matrix, min_support=0.03, use_colnames=True)\n",
    "\n",
    "# Generate association rules\n",
    "rules = association_rules(frequent_itemsets, user_cluster_matrix, metric=\"lift\", min_threshold=1.0)\n",
    "\n",
    "# Sort rules by lift and display\n",
    "rules_sorted = rules.sort_values(by=\"lift\", ascending=False)\n",
    "print(rules_sorted[['antecedents', 'consequents', 'support', 'confidence', 'lift']].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
